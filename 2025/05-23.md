# May 23, 2025

## Logistics

12-1 PM EDT / 9-10AM PDT / 4-5PM GMT

## Agenda

* Chair Update
* [Privacy Sandbox Update](https://privacysandbox.com/news/privacy-sandbox-next-steps/)
* Anti-Fraud CG Going Forward


## Resources

* [Minutes](https://docs.google.com/document/d/1BXOASTjdMd7P8vjKSJ1lQt1ct5XK_Rrp7jqDIPESODI/edit?tab=t.0#heading=h.449emh79bbfu)
* [Chair Slides](https://docs.google.com/presentation/d/13ePYTPZhUuTvGguLw1lRIxVwgSo3p-sXzq83VI2qn1Y/edit?usp=sharing)

## Minutes
Next Deep Dive on June 6, normal meeting on June 20
Reminder to use chat
Sam is our new chair! Thank you to Steven for his work as previous chair.

Next steps announced for Privacy Sandbox. Not moving forward with user choice for 3p cookies. Continuing with IP Protection, and anti-fraud work associated with it.
Brian: IP Protection is solely on incognito, correct?
Kaustubha: That is correct; other privacy features to be determined on a case-by-case basis.
Tommy: Sorry to hear that we’re not going to get some of those privacy improvements in Chrome now. Do we want to talk about where to take this CG. Not sure what the whole group wants to do; but important to have a venue somewhere on what to do about privacy-preserving ways to do anti-fraud. This CG has done cross-presentations; e.g. in IETF privacy-pass; but largely the applications for these things has been from the Google Chrome side. So, not sure about the direction for that. A direction that could be useful to keep the CG going would be to design outside the solution of a specific vendor - regardless of what’s being shipped. Can we use this as separate from what Privacy Sandbox is doing. The whole industry should have conversations around this.
Sam: Yes, open to whole industry discussion on this,
Brian: Privacy Sandbox was forcing us to think about a new model. Now that that new model is gone away. We already have things in place for anti-fraud; so could be more about extending what’s in place at the moment.
Sam: Anti-fraud in general is a reasonable direction.
Brian: Early on, had a back-and-forth on whether we should focus on specific domains. There was some interest on fraud within advertising, and payments; but they’re both materially different.
Eric: That’s a good point. Would also love to see us focus more broadly on anti-fraud efforts, independent of what’s going on on the privacy side. The concern is that most of the work we’re doing on the anti-fraud side involves adding more entropy. The way we thought about that is, since that work went hand-in-hand with the privacy work; we could make the tradeoff. We need to be careful about how do we add new solutions on the web that make the privacy angle trickier. Do we need to intertwining with privacy? Also supportive of viewing more broadly.
Sam: Disagree that we can’t make progress without regressing privacy. In various browsers, there are already solutions that provide small amounts of entropy.
Vinod: Read about the user agent’s role in these efforts. Should we start there? The role of the UA on the web - there is one around reducing entropy / privacy; should there be something about taking on more of the anti-fraud burden. So entropy can still be maintained at a level that’s supported.
Sam: In the Security Interest Group, there is a discussion about the long-term threat model. E.g. this group has talked about whether on-device attackers should be part of that. Please join that interest group, and contribute there.
Ben: Possible future discussion outside of privacy intersection. Companies like OpenAI’s Operator seems at odds with what anti-fraud wants to do. Arms race between Agentic AI and Anti-Fraud. This seems like a good place to have that discussion.
Sam: It’s happening in IETF’s web-bot-auth. I invited them to speak on June 20.
Thibault: IETF is trying to drive some of these usecases. What does it mean to be a bot; especially in some cases, there is intent that matters. E.g. training vs. RAG. How does it work to keep human access to the web. Seeing that Privacy Sandbox has some effort being reduced; but might be an opportunity to review at the multiple-vendor level. E.g. CDN perspective - client, origin, bot, etc; all need to play a role.
Brian: There is a great opportunity for us to provide signals for the user agent when a bot is operating it. We’re going to want to find some way of identifying the person who’s operating the bot, I don’t think bots should have the same level of anonymity that human beings should have. E.g. w.r.t. Advertising - you don’t need to know who the human is to know what ad to target, or to measure the effectiveness of it. Similarly, we can apply that to the AI space.
Tommy: Responding to Vinod’s comment re: role of UA. The main way that the client needs to be involved - new addition of entropy should be able to be controlled by client, get user consent, etc. Consent & explicit sharing. The problem when we have systems that weren't originally designed as anti-fraud signals, etc. is resulting in an arms race. We need to think about the entropy bits, but also about the consent bit (awareness of what’s about to be shared).
Eric: I think it would be possible for us to advocate for this. Would be more clear-cut for cases where there is clear user benefit (e.g. login safety) vs. ecosystem benefit where there may be competing incentives (e.g. with advertising, AI). We’re going to need public negotiations and navigate tradeoffs.
Sam (chair hat off): Two themes - (a) Trustworthy humans; by purveying in anonymous ways like privacy pass, others than haven't stuck. (b) New class of bots that are acceptable to access websites. Creating new social contract around this.
Brian said something about bots rights vs. human rights; but at the end of the day, humans are operating the bots. If vendors are able to make arrangements with specific websites, they may have more access than others. So there might a role for bots also to have anonymity.
Sam (chair hat on): What things do we want to prioritize? E.g. Should payments get more priority?
Per: re: comment on AI. We need to start identifying the various usecases where AI can come into play. For anti-abuse - lots of different ones. If you’re a hotel booking, you want to enable. But for ai agents clicking on ads - that doesn’t bring any value to advertisers. We need a lot of diversity on business rules. Lots of interesting topics to try to figure out there.
Brian: Would be interested to have this group work on Ai Agent specific workstream - how they represent website. What categories of interactions might there be, and how we handle each of these. We might be able to extend these to non-bot traffic too.
Vinod: Re: your point about the social contract of the web needing to change. Perhaps for the re-charter, rather than the anti-fraud angle (which involves intent); what about distinguishing between bot vs. human (i.e. operator of the site).
Brian: Should we put together a “contract for the web” from the fraud perspective?
Sam: Goes back to the threat modeling for the web. That document will have a set of concerns that people should think about when building specs or systems. There is an “AI in the browser” document also in progress, lots of room to contribute.
Brian: I was thinking about something more broadly. Consumers vs. agents.
Sam: Any thoughts on where the social contract idea could belong in the W3C?
Sam: Do we need to recharter? May not, since it’s pretty broad. Does anyone disagree?
Sam: Tommy? Do you think the charter represents the scope you’re thinking of?
Tommy: I think so? More up to everyone if we start veering into directions. My primary experience is with IETF working group charters; and in those contexts, anything is okay to discuss. Only when you’re producing work, that’s when the charter is important. We probably need more open discussion, and bounce ideas, and see if any of those seem off-charter.
Sam: We could use the Deep Dive slots for brainstorms. I think anything anti-fraud related should be fine; but broader social contract might belong elsewhere.
Eric: re:Vinod’s comment about removing intent is very interesting, will continue to think through. If we’re not going to recharter; 3 focuses areas could be:
AI
Clear user benefit (e.g. account security, payments etc.)
Advertising/ecosystem benefits at-scale. Maybe this could be combined with AI; but not sure.
Eric: If privacy is not as important, we could focus on user benefit ones for some quick wins across browsers.
Vinod: +1 to the point about having free-form discussions. Good things come out of those.
Sam: That’s great. We could also use TPAC time on open discussions. I’ve had discussions with you all which others have thought about a lot.
Brian: Agree with Eric’s proposed areas of concentration. Good start.
Per: re: TPAC. If there’s room for people to discuss what challenges they are facing, networking, etc. There’s a lot of value. You don’t find a silver bullet everyday, but you do find good solutions once-in-a-while.
Eric: Steven and I were working on hosting a face-to-face; could pick that back up with Sam.
Sam: Want to be sensitive since everyone’s busy; would prefer to see some active work for that. Otherwise, we can do something at TPAC.
Brian: Would be good to learn about new threats that folks are learning about.
Per: On that note; one of my current interests is residential proxy networks. Ping me offline if interested.
Thibault: Face-to-face, high-bandwidth is important; but async work on Slack, etc. to first start some work is preferred.
Sam: Let’s plan for TPAC; in the meantime, let’s work async.
Thibault: IETF web-bot-auth might be of interest to this group. Would like more people contributing to the drafts; e.g. on identifying agents. Like Tommy and Sam pointed out, there will be some back-and-forth between IETF and this group.
Sam: Yes, good idea to cross-pollinate between this group and more active work happening elsewhere.
Appendix
Sam: Need New Zoom - FYI, that might change for next time.
Sofia: We might get a W3C Zoom soon, but we’ll see.

